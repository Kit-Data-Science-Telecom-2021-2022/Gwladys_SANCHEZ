{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet maison n° 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. US baby names\n",
    "\n",
    "On va s'intéresser au dataset **National data** de la SSA : https://www.ssa.gov/oact/babynames/limits.html\n",
    "\n",
    "1. Télécharger le dataset des prénoms US : https://www.ssa.gov/oact/babynames/names.zip\n",
    "\n",
    "Lire la documentation associée.\n",
    "\n",
    "2. Implémenter une fonction Python qui produit un unique DataFrame avec tous les fichiers en utilisant pandas (par ex. fonction \"concat\" ou méthode \"append\"), pas de bash :)\n",
    "\n",
    "Ordre et noms des colonnes : 'year', 'name', 'gender', 'births'\n",
    "\n",
    "Le DataFrame doit être trié selon l'année croissante puis selon l'ordre défini par les différents fichiers (voir la documentation du dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier_source = Path(\"names\\\\\")\n",
    "filesUS = dossier_source.glob(\"*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui extrait l'année correspondant à chaque fichier\n",
    "def annee(fichier):\n",
    "    p = re.compile('.*yob(....).txt')\n",
    "    return p.match(os.path.basename(fichier)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names us\n",
    "def df_names_us():\n",
    "    df = pd.DataFrame(columns=['year', 'name', 'gender', 'births'])\n",
    "    for file in filesUS:\n",
    "        df1 = pd.read_csv(file, names=['name', 'gender', 'births'])\n",
    "        yob = annee(file)\n",
    "        df1.insert(0,'year',yob)\n",
    "        df = df.append(df1, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prénoms français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset **Fichiers France hors Mayotte** de l'INSEE :  https://www.insee.fr/fr/statistiques/2540004/\n",
    "\n",
    "L'idée est de charger les données et ensuite de les conformer au DataFrame des prénoms US. Ainsi, toute manipulation sur le DataFrame des prénoms US pourra être directement réutilisée avec le DataFrame des prénoms français.\n",
    " \n",
    "1. Télécharger le dataset des prénoms français : https://www.insee.fr/fr/statistiques/fichier/2540004/nat2020_csv.zip\n",
    "\n",
    "\n",
    "Lire la documentation, ça peut être utile...\n",
    " \n",
    "2. Implémenter une fonction Python qui produit un DataFrame avec les prénoms français en prenant le DataFrame des prénoms US comme modèle :\n",
    " \n",
    " - Même ordre et mêmes noms des colonnes : year, name, gender, births\n",
    " - Mêmes dtypes pour les colonnes\n",
    " - Mêmes valeurs pour la colonne 'gender'\n",
    " - Seuls les prénoms de 2 caractères et plus sont conservés\n",
    " - La casse des prénoms doit être identique : initiales en majuscule, autres lettres en minuscule\n",
    " - Les lignes avec des données inutilisables doivent être supprimées\n",
    " - Les données sont triées à l'identique : années (↑), puis gender (↑), puis births (↓) et enfin name (↑)\n",
    " - L'index du DataFrame doit aller de 0 à N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On définit le path jusqu'au fichier\n",
    "fileFR = Path(\"nat2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names fr\n",
    "def df_names_fr():\n",
    "    df_FR = pd.read_csv(fileFR, sep=';')\n",
    "    \n",
    "    #Nom et ordre des colonnes\n",
    "    df_FR = df_FR.rename(columns={\"sexe\": \"gender\", \"preusuel\": \"name\",  \"annais\": \"year\",  \"nombre\": \"births\"})\n",
    "    df_FR = df_FR[['year','name','gender','births']]\n",
    "    \n",
    "    df_FR['gender']=df_FR['gender'].map({1:\"M\", 2:\"F\"})\n",
    "    \n",
    "    #même type que les données US\n",
    "    df_FR.astype('object').dtypes\n",
    "    \n",
    "    #Suppression des prénoms à une lettre, es \"prénoms rares\", des années \"XXXX\"\n",
    "    df_FR = df_FR.drop(df_FR[df_FR['name'].str.len() == 1].index)\n",
    "    df_FR = df_FR.drop(df_FR[df_FR['name'] == \"_PRENOMS_RARES\"].index)    \n",
    "    df_FR = df_FR.drop(df_FR[df_FR['year'] == \"XXXX\"].index)    \n",
    "\n",
    "    #Changement de la casse des prénoms\n",
    "    df_FR[\"name\"] = df_FR[\"name\"].apply(lambda x: str(x).title())\n",
    "    \n",
    "    #Tri\n",
    "    df_FR = df_FR.sort_values(by=['year','gender','births','name'], ascending=[True, True, False, True])\n",
    "    \n",
    "    #index\n",
    "    df_FR.index = pd.RangeIndex(stop=len(df_FR.index))\n",
    " \n",
    "    return df_FR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taux de change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va s'intéresser au dataset des cours des devises de la Banque de France :  http://webstat.banque-france.fr/fr/#/downloading\n",
    "\n",
    "L'idée est de charger les données, de les nettoyer et de pouvoir accéder aux cours de certaines devises à partir de leur code ISO3.\n",
    " \n",
    "1. Utiliser le dataset des taux de change fourni.\n",
    "\n",
    "\n",
    "2. Implémenter une fonction qui produit un DataFrame avec les taux de change par date pour une liste de codes ISO3 de devises passée en argument. L'index du DataFrame doit correspondre aux dates (voir la fonction pd.to_datetime() avec le format '%d/%m/%Y'). Les colonnes du DataFrame doivent correspondre aux devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour traduire les strings en ISO quand c'est possible\n",
    "def iso(string):\n",
    "    regexISO = re.compile('^.*\\(([A-Z]{3})\\)')\n",
    "    if regexISO.match(string):\n",
    "        return(regexISO.match(string).group(1))\n",
    "    else: return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taux de change\n",
    "def df_taux_change(devises):\n",
    "    #on importe le fichier source\n",
    "    data = pd.read_csv(\"Webstat_Export_20210929.csv\", sep=\";\")\n",
    "    #on change les noms des colonnes pour correspondre à un code ISO, et on enlève les premières lignes\n",
    "    data = data.rename(mapper=iso,axis=\"columns\")\n",
    "    data = data.drop(list(range(5)))\n",
    "    \n",
    "    #Transformation des dates en \"datetime\" et utilisation comme index\n",
    "    data[\"Titre :\"] = pd.to_datetime(data[\"Titre :\"], infer_datetime_format=True)\n",
    "    data.set_index(\"Titre :\", inplace=True)\n",
    "    \n",
    "    #Conversion de tous les taux en floats\n",
    "    data.replace([\",\", \"-\"], [\".\", np.nan], inplace=True, regex=True)\n",
    "    data = data.astype('float')\n",
    "    \n",
    "    #suppression des lignes contenant des NaN\n",
    "    data = data.dropna()\n",
    "    \n",
    "    df = data[devises]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Lesson4Tests(unittest.TestCase):\n",
    "    def test_df_names_us(self):\n",
    "        df = df_names_us()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 2020863)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "        \n",
    "    def test_df_names_fr(self):\n",
    "        df = df_names_fr()\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['year', 'name', 'gender', 'births'])\n",
    "        # lignes\n",
    "        self.assertEqual(len(df), 630407)\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.range.RangeIndex))\n",
    "        # test names\n",
    "        self.assertTrue(df.loc[df['name'].str.contains('^[A-Z]+(?:-[A-Z]+)?$')].empty)\n",
    "        # test gender\n",
    "        self.assertEqual(len(df), len(df.loc[df['gender']=='F']) + len(df.loc[df['gender']=='M']))\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n",
    "\n",
    "    def test_df_taux_change(self):\n",
    "        df = df_taux_change(['CHF', 'GBP', 'USD'])\n",
    "        # colonnes\n",
    "        self.assertEqual(list(df.columns), ['CHF', 'GBP', 'USD'])\n",
    "        # index\n",
    "        self.assertTrue(isinstance(df.index, pd.core.indexes.datetimes.DatetimeIndex))\n",
    "        # types taux\n",
    "        self.assertTrue((df.dtypes == 'float').all())\n",
    "        # test NaN\n",
    "        self.assertTrue(df.loc[df.isnull().any(axis=1)].empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson4Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_df_names_fr (__main__.Lesson4Tests) ... ok\n",
      "test_df_names_us (__main__.Lesson4Tests) ... ok\n",
      "test_df_taux_change (__main__.Lesson4Tests) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 16.148s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
